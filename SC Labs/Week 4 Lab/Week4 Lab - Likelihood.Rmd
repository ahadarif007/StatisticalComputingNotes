---
title: "Week 4 Lab: Likelihood"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

------------------------------------------------------------------------

# Introduction

## What is "Likelihood"?

Imagine you flip a coin 10 times and get 8 heads. You might ask: *"Is this a fair coin?"* The likelihood function helps you answer that question by telling you **how plausible each possible value of the unknown parameter is**, given the data you observed.

Here's the key idea in plain English:

> **Likelihood** asks: "If the true parameter were *this* value, how probable would my observed data be?"

We calculate this for *every* possible parameter value, and whichever value makes our data the **most probable** is our best guess. That best guess is called the **Maximum Likelihood Estimate (MLE)**.

### The maths (don't panic!)

If we observe data points $x_1, x_2, \ldots, x_n$ and our model says each data point follows a distribution with formula $f(x \mid \theta)$, then the **likelihood function** is:

$$
L(\theta) = \prod_{i=1}^n f(x_i \mid \theta)
$$

This is just the **product** (multiply together) of the probability of each data point. The $\theta$ is the unknown parameter we're trying to estimate.

### Why do we use the "log-likelihood"?

Multiplying many small probabilities together gives a *tiny* number — so tiny that computers can't handle it precisely (they get rounding errors). Taking the **logarithm** converts the product into a **sum**, which is much more numerically stable:

$$
\ell(\theta) = \sum_{i=1}^n \log f(x_i \mid \theta)
$$

-   The **log-likelihood** ($\ell$) and the likelihood ($L$) reach their peak at exactly the same value of $\theta$, so maximising either one gives the same answer.
-   From now on, we'll almost always work with the **log-likelihood**.

### The Maximum Likelihood Estimate (MLE)

The **MLE** $\hat{\theta}$ is simply the value of $\theta$ that makes $\ell(\theta)$ as large as possible — i.e., the peak of the log-likelihood curve.

------------------------------------------------------------------------

# 1. Computing and Plotting Log-Likelihoods

In R, probability distribution functions start with the letter `d` (for "density"):

| Distribution | R function | Example                |
|--------------|------------|------------------------|
| Poisson      | `dpois()`  | Counting rare events   |
| Normal       | `dnorm()`  | Bell-curve data        |
| Binomial     | `dbinom()` | Success/failure trials |
| Exponential  | `dexp()`   | Waiting times          |

All of these accept a `log = TRUE` argument, which returns $\log f(x \mid \theta)$ directly. This makes computing log-likelihoods easy — just `sum()` up the log-densities!

## Worked Example: Horse Kick Data

This is a famous historical dataset: it counts the **number of soldiers killed by horse kicks** per year in 14 Prussian cavalry corps over 20 years (200 observations total).

Since we're counting *how many times* a rare event happened, a **Poisson distribution** is a natural choice. The Poisson has one parameter: **λ (lambda)**, the average number of events.

The Poisson log-likelihood is:

$$
\ell(\lambda) = \sum_{i=1}^n \left[ x_i \log(\lambda) - \lambda - \log(x_i!) \right]
$$

Don't worry about memorising this formula — the key point is that R's `dpois(..., log = TRUE)` does all the work for us.

```{r horse-kick}
x <- rep(0:4, c(109, 65, 22, 3, 1))  ## Horse kick data: value repeated by frequency

# Define the log-likelihood as a function of lambda
loglik <- function(lambda) sum(dpois(x, lambda, log = TRUE))

# Plot the log-likelihood over a range of lambda values
curve(Vectorize(loglik)(x), from = 0.1, to = 2,
      xlab = expression(lambda),
      ylab = expression(ell(lambda)),
      main = "Log-likelihood for Horse Kick Data (Poisson)",
      col = "steelblue", lwd = 2)

# Add a vertical line at the sample mean (which is the MLE for Poisson)
abline(v = mean(x), col = "tomato", lty = 2, lwd = 2)
legend("topright", legend = c("Log-likelihood", expression(hat(lambda) == bar(x))),
       col = c("steelblue", "tomato"), lty = c(1, 2), lwd = 2)
```

> **What to notice:** The curve has a clear peak. The red dashed line shows the **sample mean** $\bar{x}$, and it lands right at the peak. This isn't a coincidence — for the Poisson distribution, the MLE is *always* equal to the sample mean: $\hat{\lambda} = \bar{x}$.

------------------------------------------------------------------------

## (a) Birth Weight of Infants of Smokers

### The scenario

The `birthwt` dataset (originally from the `MASS` package) contains birth weight data from a Massachusetts hospital. We'll focus on infants born to **smoking mothers** and model their birth weights (converted to kg) using a **Normal distribution**.

To keep things simple for now, we'll **assume the standard deviation is known** ($\sigma = 1$) and only estimate the **mean** ($\mu$).

### The maths

If $X_i \sim N(\mu, 1)$, the log-likelihood as a function of $\mu$ is:

$$
\ell(\mu) = -\frac{n}{2}\log(2\pi) - \frac{1}{2}\sum_{i=1}^n (x_i - \mu)^2
$$

The important part is the $(x_i - \mu)^2$ term — the log-likelihood penalises values of $\mu$ that are far from the data points. The best $\mu$ is the one that minimises the total squared distance to all data points, which turns out to be... the sample mean! (No surprise there.)

```{r birthwt-data}
birthwt <- read.csv("birthwt.csv")

# Extract birth weights (in grams) for smoking mothers and convert to kg
bwt_smokers <- birthwt$bwt[birthwt$smoke == "yes"] / 1000

cat("Number of observations:", length(bwt_smokers), "\n")
cat("Sample mean:", round(mean(bwt_smokers), 3), "kg\n")
hist(bwt_smokers, breaks = 15, col = "lightblue", border = "white",
     main = "Birth Weights of Infants (Smokers)",
     xlab = "Birth weight (kg)")
```

**Your turn:** The code below writes a log-likelihood function and plots it. The function `loglik_mu(mu)` computes the log-likelihood by summing up the log-densities of a Normal distribution with mean `mu` and sd = 1.

```{r bwt-loglik}
## Write your log-likelihood function here
loglik_mu <- function(mu) {
  sum(dnorm(bwt_smokers, mean = mu, sd = 1, log = TRUE))
}

## Plot the log-likelihood
curve(Vectorize(loglik_mu)(x), from = 1, to = 5,
      xlab = expression(mu), ylab = expression(ell(mu)),
      main = "Log-likelihood for Birth Weight (Normal, sd=1)",
      col = "steelblue", lwd = 2)

## Add a vertical line at the sample mean (the theoretical MLE)
abline(v = mean(bwt_smokers), col = "tomato", lty = 2, lwd = 2)
legend("topright", legend = c("Log-likelihood", expression(hat(mu) == bar(x))),
       col = c("steelblue", "tomato"), lty = c(1, 2), lwd = 2)
```

> **Think about it:** For a Normal distribution with known $\sigma$, the MLE for $\mu$ is always the sample mean $\bar{x}$. Does the peak of your plot confirm this?

------------------------------------------------------------------------

## (b) Seed Germination Data

### The scenario

We planted **5 batches** of **20 seeds each** and counted how many seeds germinated in each batch. We want to estimate the **germination probability** $p$ — i.e., the chance that any individual seed will germinate.

Each batch is modelled as $Y_i \sim \text{Binomial}(20, p)$, which means: "out of 20 seeds, each with probability $p$ of germinating, how many actually germinate?"

```{r seed-data, echo=FALSE, eval=TRUE}
set.seed(12345)
y <- rbinom(5, 20, p = 0.65)
print(y)
```

### The log-likelihood

$$
\ell(p) = \sum_{i=1}^n \left[ \log \binom{20}{y_i} + y_i \log(p) + (20 - y_i)\log(1-p) \right]
$$

Again, R's `dbinom(..., log = TRUE)` handles all of this for us.

**Your turn:** The code below plots the log-likelihood for $p$ between 0 and 1. The peak tells us the most likely germination probability.

```{r seed-loglik}
## Write your log-likelihood function here
loglik_p <- function(p) {
  sum(dbinom(y, 20, prob = p, log = TRUE))
}

## Plot the log-likelihood
curve(Vectorize(loglik_p)(x), from = 0.01, to = 0.99,
      xlab = "p", ylab = expression(ell(p)),
      main = "Log-likelihood for Germination Probability (Binomial)",
      col = "steelblue", lwd = 2)

## Add vertical line at the MLE: p_hat = mean(y) / 20
abline(v = mean(y) / 20, col = "tomato", lty = 2, lwd = 2)
legend("topright", legend = c("Log-likelihood", expression(hat(p) == bar(y)/20)),
       col = c("steelblue", "tomato"), lty = c(1, 2), lwd = 2)
```

> **Think about it:** For the Binomial distribution, the MLE is $\hat{p} = \frac{\text{total successes}}{\text{total trials}} = \frac{\sum y_i}{5 \times 20}$. This is just the overall proportion of seeds that germinated. Does the red line match the peak?

------------------------------------------------------------------------

## (c) Extension: Exponential Waiting Times *(optional challenge)*

### The scenario

Suppose we're timing how long (in minutes) we wait between events — like customers arriving at a coffee shop. The **Exponential distribution** is the standard model for this kind of "time between events" data.

The Exponential has one parameter: the **rate** $\lambda$ (lambda), which is the average number of events per unit time. Its density is $f(x \mid \lambda) = \lambda e^{-\lambda x}$ for $x > 0$.

```{r waiting-times}
set.seed(99)
w <- rexp(30, rate = 0.4)
round(w, 2)
```

**Your turn:** Write a log-likelihood for $\lambda$ and plot it. The **analytical MLE** for the Exponential rate is $\hat{\lambda} = \frac{1}{\bar{x}}$ (one divided by the sample mean).

```{r exp-loglik}
## Write your log-likelihood function here
loglik_rate <- function(lambda) {
  sum(dexp(w, rate = lambda, log = TRUE))
}

## Plot the log-likelihood
curve(Vectorize(loglik_rate)(x), from = 0.1, to = 1,
      xlab = expression(lambda), ylab = expression(ell(lambda)),
      main = "Log-likelihood for Exponential Waiting Times",
      col = "steelblue", lwd = 2)

## The MLE for the Exponential rate is 1/mean(w)
abline(v = 1 / mean(w), col = "tomato", lty = 2, lwd = 2)
legend("topright", legend = c("Log-likelihood", expression(hat(lambda) == 1/bar(w))),
       col = c("steelblue", "tomato"), lty = c(1, 2), lwd = 2)
```

------------------------------------------------------------------------

# 2. Interlude: Likelihood Surfaces

## What happens when there are TWO unknown parameters?

So far, every model had just **one** unknown parameter (λ, μ, or p), so the log-likelihood was a **curve** (a 2D plot). But what if we don't know *both* the mean AND the standard deviation? Then the log-likelihood becomes a **surface** over a 2D grid — like a mountain landscape where we're looking for the highest peak.

For example, if $X_i \sim N(\mu, \sigma^2)$ with both $\mu$ and $\sigma$ unknown, the log-likelihood is:

$$
\ell(\mu, \sigma) = -n\log(\sigma) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2 + \text{const}
$$

Here we **visualise** this surface using a contour plot (like a topographic map — each coloured band represents a different "altitude" of log-likelihood):

```{r likelihood-surface, fig.width=7, fig.height=5}
loglik_2d <- function(mu, sigma) {
  if (sigma <= 0) return(-Inf)
  sum(dnorm(bwt_smokers, mean = mu, sd = sigma, log = TRUE))
}

mu_vals    <- seq(2.5, 3.5, length.out = 100)
sigma_vals <- seq(0.4, 1.2, length.out = 100)

ll_surface <- outer(mu_vals, sigma_vals, Vectorize(loglik_2d))

filled.contour(mu_vals, sigma_vals, ll_surface,
               xlab = expression(mu), ylab = expression(sigma),
               main = "Log-likelihood Surface: Normal(μ, σ)",
               color.palette = function(n) hcl.colors(n, "YlOrRd", rev = TRUE))
```

> **What to notice:**
>
> -   The **darkest region** is where the log-likelihood is highest — that's where the MLE lives.
> -   The **shape of the contours** (elongated? circular?) tells us about the **relationship** between uncertainty in $\mu$ and uncertainty in $\sigma$. This is a preview of the idea of **confidence regions** — zones where the true parameter is likely to be.

------------------------------------------------------------------------

# 3. Fun with Derivatives

## Why do we need derivatives?

To find the MLE *analytically* (i.e., with pen and paper), we take the **derivative** of the log-likelihood, set it equal to zero, and solve for the parameter. The derivative tells us the "slope" of the log-likelihood curve — at the peak, the slope is zero (flat).

R has a built-in function `D()` that can compute **symbolic derivatives** — it takes a mathematical expression and tells you its derivative. This is handy for checking your pen-and-paper work!

## Worked Example

```{r deriv-example}
# Derivative of log(t) with respect to t
D(expression(log(t)), "t")

# Derivative of t^3 - 2*t with respect to t
D(expression(t^3 - 2*t), "t")
```

**How to read the output:** R returns the derivative as an R expression. For example: - `D(expression(log(t)), "t")` returns `1/t` (because the derivative of $\log(t)$ is $\frac{1}{t}$). - `D(expression(t^3 - 2*t), "t")` returns `3 * t^2 - 2` (the power rule!).

**Your turn:** Use `D()` to find the derivative of each of the following with respect to $t$.

------------------------------------------------------------------------

## (a) $a + bt + ct^2$

This is a **quadratic** (parabola). What does its derivative look like?

```{r deriv-a}
## Find the derivative with respect to t
D(expression(a + b*t + c*t^2), "t")
```

> **What to notice:** The derivative is a **linear** function of $t$ (i.e., $b + 2ct$). This makes sense — the slope of a parabola changes at a constant rate. Setting it to zero and solving for $t$ gives $t = -b / (2c)$, which is the vertex (peak or valley) of the parabola.

------------------------------------------------------------------------

## (b) $e^{t^2}$

```{r deriv-b}
## Find the derivative with respect to t
D(expression(exp(t^2)), "t")
```

------------------------------------------------------------------------

## (c) $t - \log(t)$

```{r deriv-c}
## Find the derivative with respect to t
D(expression(t - log(t)), "t")
```

> **Your turn:** Set the derivative equal to zero and solve for $t$. The derivative is $1 - \frac{1}{t}$. Setting $1 - \frac{1}{t} = 0$ gives $t = 1$.

We can also find this numerically using `uniroot()`, which searches for where a function equals zero:

```{r}
ddt <- function(t) eval(expression(1-1/t))
uniroot(ddt, interval = c(0.01, 10))$root
```

The answer is $t = 1$. The tiny difference from exactly 1 is just floating-point rounding — numerical methods aren't perfectly exact, but they get extremely close.

------------------------------------------------------------------------

## (d) Extension: The Poisson Log-Likelihood *(optional)*

The Poisson log-likelihood (ignoring constant terms that don't depend on $\lambda$) is:

$$\ell(\lambda) = n\bar{x} \cdot \log(\lambda) - n\lambda$$

**Your turn:** Differentiate with respect to $\lambda$, set the result to zero, and confirm that $\hat{\lambda} = \bar{x}$.

```{r deriv-d}
## Differentiate the Poisson log-likelihood with respect to lambda
# Treat n and xbar as constants
ploglikD <- D(expression(xbar * n * log(lambda) - n * lambda), "lambda")
ploglikD
```

### Solving by hand

R gives us the derivative: $\frac{n\bar{x}}{\lambda} - n$. Setting this to zero:

$$\frac{n\bar{x}}{\lambda} - n = 0 \quad \Rightarrow \quad \frac{n\bar{x}}{\lambda} = n \quad \Rightarrow \quad \hat{\lambda} = \bar{x}$$

> **Note:** `uniroot()` can't solve this symbolically (it needs actual numbers for $n$ and $\bar{x}$), but you can easily solve it by hand as shown above. This confirms that the Poisson MLE is the sample mean!

------------------------------------------------------------------------

# 4. Numerical Maximum Likelihood with `mle()`

## Why do we need numerical methods?

So far, we've been lucky — the Poisson, Normal, and Binomial all have **closed-form MLEs** (we can solve for the answer with pen and paper). But many realistic models don't have neat formulas. In those cases, we need the computer to **search** for the peak of the log-likelihood numerically.

## How `mle()` works

R's `mle()` function (from the `stats4` package) does this for us. Here's what it needs:

| Argument | What it is | Why |
|------------------------|------------------------|------------------------|
| **A function** | The **negative** log-likelihood | `mle()` uses a minimiser internally, so we flip the sign: minimising $-\ell$ is the same as maximising $\ell$ |
| `start` | A list of **initial guesses** for the parameters | The algorithm needs a starting point to begin its search |
| `nobs` | The number of observations | Used for calculating information criteria like AIC |

> **Why "negative" log-likelihood?** It's a convention in R. The underlying algorithm (`optim()`) is designed to *minimise* functions. Minimising $-\ell(\theta)$ is mathematically identical to maximising $\ell(\theta)$.

```{r load-stats4}
library(stats4)
```

## Worked Example: Horse Kick Data

Let's redo the horse kick example, but now using `mle()` instead of finding the answer by hand:

```{r mle-poisson}
x <- rep(0:4, c(109, 65, 22, 3, 1))

negloglik_pois <- function(lambda) -sum(dpois(x, lambda, log = TRUE))

fit_pois <- mle(negloglik_pois, start = list(lambda = 1), nobs = length(x))
summary(fit_pois)
```

### How to read the output

-   **Estimate:** This is the MLE $\hat{\lambda}$ — the value of lambda that maximises the log-likelihood. It should match the sample mean $\bar{x}$ = `r round(mean(x), 4)`.
-   **Std. Error:** This tells you how "certain" we are about the estimate. A smaller standard error means more certainty. It's derived from the **curvature** of the log-likelihood at its peak — a sharply peaked curve means more precision.

## Always check convergence!

When you call `mle()`, the fitted object stores detailed information about the optimisation process. You can access this with `fit@details`. **The most important thing to check** is the convergence code:

| Code         | Meaning                                       |
|--------------|-----------------------------------------------|
| **0**        | ✅ Success! The algorithm converged.          |
| **1**        | ⚠️ Hit the iteration limit before converging. |
| **52 or 54** | ❌ Numerical problems with the likelihood.    |

> **Warning:** `mle()` will **not** throw an error or warning if it fails to converge — it will just return whatever parameter value it ended up at, which could be completely wrong. **Always** check `fit@details$convergence == 0` before trusting your results!

```{r}
fit_pois@details
```

------------------------------------------------------------------------

## (a) MLE for Birth Weight (Normal, sd = 1)

**Your turn:** Using the `loglik_mu` function you wrote in Section 1(a), compute the MLE for $\mu$ using `mle()`. Remember: `mle()` needs the **negative** log-likelihood, so we just negate it.

```{r mle-normal}
## Define the negative log-likelihood
negloglik_mu <- function(mu) -loglik_mu(mu)

## Fit the model
fit_mu <- mle(negloglik_mu, start = list(mu = 3), nobs = length(bwt_smokers))
summary(fit_mu)
fit_mu@details
```

> **Check:** Does the MLE match the sample mean? Did the convergence code equal 0? If yes to both, everything worked! ✅

------------------------------------------------------------------------

## (b) MLE for Seed Germination (Binomial)

**Your turn:** Using the `loglik_p` function from Section 1(b), compute the MLE for the germination probability $p$.

**Special consideration:** The parameter $p$ must stay between 0 and 1 (it's a probability!). We use `method = "Brent"` with `lower` and `upper` bounds to enforce this constraint. The Brent method is specifically designed for **single-parameter bounded optimisation**.

```{r mle-binomial}
## Define the negative log-likelihood
negloglik_p <- function(p) -loglik_p(p)

## Fit the model — use method="Brent" for single-parameter bounded optimisation
fit_p <- mle(negloglik_p, start = list(p = 0.5), nobs = length(y),
             method = "Brent", lower = 0.001, upper = 0.999)
summary(fit_p)

## Compare to analytic MLE
cat("Analytic MLE p_hat = sum(y) / (5*20) =", sum(y) / (5 * 20), "\n")
```

> **Check:** The MLE from `mle()` should match $\frac{\sum y_i}{5 \times 20}$ (the total number of germinated seeds divided by the total number of seeds planted). Do they agree? ✅

------------------------------------------------------------------------

## (c) MLE for Birth Weight, sd unknown

### Making it more realistic

In Section 4(a), we assumed we *knew* that $\sigma = 1$. In real life, we almost never know the standard deviation in advance. So now let's estimate **both** $\mu$ AND $\sigma$ at the same time.

This means our negative log-likelihood takes **two arguments**, and `mle()` will search over a **2D parameter space** — exactly the surface you visualised in Section 2.

```{r mle-both}
negloglik_both <- function(mu, sigma) {
  if (sigma <= 0) return(Inf)
  -sum(dnorm(bwt_smokers, mean = mu, sd = sigma, log = TRUE))
}

fit_both <- mle(negloglik_both, start = list(mu = 3, sigma = 0.7),
                nobs = length(bwt_smokers))
summary(fit_both)
fit_both@details$convergence

cat("Sample mean:", round(mean(bwt_smokers), 4), "\n")
cat("Sample sd:  ", round(sd(bwt_smokers), 4), "\n")
```

### Why doesn't $\hat{\sigma}$ exactly match `sd()`?

You'll notice a small difference between the MLE for $\sigma$ and R's `sd()` function. This is because:

-   **MLE** divides by $n$ (the sample size).
-   **`sd()` in R** divides by $n - 1$ (this is called **Bessel's correction**, which gives a less biased estimate for small samples).

The difference shrinks as the sample gets larger, and for practical purposes they're very close.

------------------------------------------------------------------------

# 5. Optimisation Methods

## What's happening "under the hood"?

When you call `mle()`, it uses R's general-purpose optimisation function `optim()` to search for the peak of the log-likelihood. But *how* does `optim()` search? There are several different strategies (called **algorithms**), each with pros and cons.

Think of it like searching for the highest point on a mountain in dense fog:

| Method | Analogy | How it works |
|------------------------|------------------------|------------------------|
| **Nelder-Mead** | Wander around and keep track of which directions went uphill | Doesn't need to know the slope (derivative-free). Robust but slow. |
| **BFGS** | Use a compass *and* read the slope of the ground under your feet | Uses gradient (slope) information to take smart steps. Fast and efficient. |
| **Gradient Ascent** | Always walk in the steepest uphill direction, one small step at a time | The simplest method. Easy to understand but can be slow. |

### More detail on each method

**Nelder-Mead** (the default in `optim()`):

-   Creates a geometric shape (called a "simplex") in parameter space and moves it around — reflecting, expanding, or shrinking it — to home in on the peak.
-   **Pros:** No derivatives needed. Very robust (hard to break).
-   **Cons:** Can be slow, especially with many parameters.

**BFGS** (Broyden–Fletcher–Goldfarb–Shanno):

-   A "quasi-Newton" method. Newton's method uses the gradient (first derivative) AND the Hessian (second derivative) to make very smart decisions about where to step next. BFGS *approximates* the Hessian from past gradient calculations, saving computation.
-   **Pros:** Much faster than Nelder-Mead on smooth problems.
-   **Cons:** Needs the log-likelihood to be smooth (no sudden jumps or flat spots).

**Gradient Ascent** (the DIY method):

-   At each step, compute the slope (gradient) and take a small step uphill. The step size $\gamma$ is called the **learning rate**:

$$
\theta^{(t+1)} = \theta^{(t)} + \gamma \cdot \frac{\partial \ell}{\partial \theta}\bigg|_{\theta^{(t)}}
$$

-   **Pros:** Very simple and easy to implement by hand.
-   **Cons:** Sensitive to the learning rate $\gamma$. Too big → overshoot and oscillate. Too small → painfully slow.

### What does `mle()` use?

`mle()` uses **BFGS** by default (or its memory-efficient cousin **L-BFGS-B** when you supply parameter bounds). So every time you called `mle()` in Section 4, you were already using a quasi-Newton method!

## Worked Example: Comparing Methods on the Horse Kick Data

Here we use `optim()` directly (instead of `mle()`) to see the difference between Nelder-Mead and BFGS. Then we implement gradient ascent by hand.

```{r optim-compare}
x <- rep(0:4, c(109, 65, 22, 3, 1))
negloglik_pois <- function(lambda) -sum(dpois(x, lambda, log = TRUE))

# Nelder-Mead (derivative-free)
fit_nm   <- optim(par = 1, fn = negloglik_pois, method = "Nelder-Mead")

# BFGS (quasi-Newton, uses gradient)
fit_bfgs <- optim(par = 1, fn = negloglik_pois, method = "BFGS")

cat("Nelder-Mead estimate:", round(fit_nm$par, 6),   "  Iterations:", fit_nm$counts[1], "\n")
cat("BFGS estimate:       ", round(fit_bfgs$par, 6), "  Iterations:", fit_bfgs$counts[1], "\n")
cat("True MLE (mean x):   ", round(mean(x), 6), "\n")
```

### Gradient Ascent by hand

Now let's implement gradient ascent ourselves. For the Poisson log-likelihood:

-   The derivative (gradient) is: $\frac{\partial \ell}{\partial \lambda} = \frac{\sum x_i}{\lambda} - n$
-   At each iteration, we update: $\lambda_{\text{new}} = \lambda_{\text{old}} + \gamma \times \text{gradient}$

```{r gradient-ascent-poisson}
# Gradient ascent by hand for the Poisson log-likelihood.
# The derivative of ell(lambda) with respect to lambda is: sum(x)/lambda - n
grad_loglik_pois <- function(lambda) sum(x) / lambda - length(x)

gamma  <- 0.001  # learning rate
lambda <- 0.5    # starting value
n_iter <- 500

trace <- numeric(n_iter)
for (i in seq_len(n_iter)) {
  lambda   <- lambda + gamma * grad_loglik_pois(lambda)
  trace[i] <- lambda
}

plot(trace, type = "l", col = "steelblue", lwd = 2,
     xlab = "Iteration", ylab = expression(lambda),
     main = "Gradient Ascent: Poisson MLE")
abline(h = mean(x), col = "tomato", lty = 2, lwd = 2)
legend("bottomright", legend = c("Gradient ascent", expression(hat(lambda) == bar(x))),
       col = c("steelblue", "tomato"), lty = 1:2, lwd = 2)

cat("Gradient ascent estimate after", n_iter, "iterations:", round(lambda, 6), "\n")
```

> **What to notice:** Gradient ascent eventually reaches the correct answer, but it takes **many more iterations** than BFGS. Try changing the learning rate:
>
> -   `gamma = 0.01` → Faster convergence (bigger steps)
> -   `gamma = 0.0001` → Slower convergence (tinier steps)
> -   `gamma = 0.1` → Might overshoot and oscillate!

## Your turn: Comparing Methods on Birth Weight Data

Using the `bwt_smokers` data from Section 1(a), fit the Normal log-likelihood (with sd = 1) using `optim()` with three different methods. Compare which converges fastest and whether they all agree on the answer.

```{r optim-birthwt}
negloglik_mu <- function(mu) -loglik_mu(mu)

# Nelder-Mead (derivative-free)
fit_nm_bwt   <- optim(par = 3, fn = negloglik_mu, method = "Nelder-Mead")

# BFGS (quasi-Newton)
fit_bfgs_bwt <- optim(par = 3, fn = negloglik_mu, method = "BFGS")

# L-BFGS-B (bounded quasi-Newton, mu must be positive)
fit_lbfgsb_bwt <- optim(par = 3, fn = negloglik_mu, method = "L-BFGS-B", lower = 0)

cat("Nelder-Mead  estimate:", round(fit_nm_bwt$par, 6),
    "  Fn evals:", fit_nm_bwt$counts[1],
    "  Convergence:", fit_nm_bwt$convergence, "\n")
cat("BFGS         estimate:", round(fit_bfgs_bwt$par, 6),
    "  Fn evals:", fit_bfgs_bwt$counts[1],
    "  Convergence:", fit_bfgs_bwt$convergence, "\n")
cat("L-BFGS-B     estimate:", round(fit_lbfgsb_bwt$par, 6),
    "  Fn evals:", fit_lbfgsb_bwt$counts[1],
    "  Convergence:", fit_lbfgsb_bwt$convergence, "\n")
cat("Sample mean (true MLE):", round(mean(bwt_smokers), 6), "\n")
```

------------------------------------------------------------------------

# 6. MLE for the Gamma Distribution via Gradient Ascent

## Why is this section special?

The **Gamma distribution** is our first example of a model where there is **no closed-form MLE** — you *cannot* solve for the answer with pen and paper. This is why numerical methods (like gradient ascent and `mle()`) are essential in practice.

### What is the Gamma distribution?

The Gamma distribution is used to model **positive, right-skewed data** — things like waiting times, rainfall amounts, and insurance claims. Its density is:

$$
f(x \mid \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x}, \quad x > 0
$$

where:

-   $\alpha > 0$ is the **shape** parameter (controls the curve's shape — small $\alpha$ = very skewed, large $\alpha$ = more symmetric)
-   $\beta > 0$ is the **rate** parameter (controls how stretched out the distribution is)

### The tricky part

While $\beta$ does have a closed-form MLE ($\hat{\beta} = \alpha / \bar{x}$), the shape parameter $\alpha$ does **not**. Its log-likelihood involves the **Gamma function** $\Gamma(\alpha)$, which doesn't have a nice inverse. So we need numerical methods!

### The gradient for $\alpha$

If we plug in $\hat{\beta} = \alpha / \bar{x}$ (the closed-form MLE for $\beta$), we can write the derivative of the log-likelihood with respect to $\alpha$ as:

$$
\frac{\partial \ell(\alpha)}{\partial \alpha} = n\log\alpha - n\log\bar{x} - n \cdot \psi(\alpha) + \sum_{i=1}^n \log(x_i)
$$

where $\psi(\alpha)$ is the **digamma function** — the derivative of $\log\Gamma(\alpha)$. R provides this as `digamma(alpha)`.

### Our data

```{r gamma-data}
x_gamma <- c(67.98, 61, 49.82)
cat("Sample:", x_gamma, "\n")
cat("Sample mean:", round(mean(x_gamma), 4), "\n")
cat("Sum of log(x):", round(sum(log(x_gamma)), 4), "\n")
```

### Gradient ascent for $\alpha$

**Your turn:** The code below implements gradient ascent. It:

1.  Computes the gradient (slope) of the log-likelihood at the current $\alpha$.
2.  Takes a small step in the uphill direction: $\alpha_{\text{new}} = \alpha_{\text{old}} + \gamma \times \text{gradient}$.
3.  Repeats until the changes become negligibly small.

```{r gamma-gradient-ascent}
gradient <- function(alpha, sample) {
  n       <- length(sample)
  barx    <- mean(sample)
  sum_log <- sum(log(sample))
  grad    <- n * log(alpha) - n * log(barx) - n * digamma(alpha) + sum_log
  return(grad)
}

grad_ascent_gamma <- function(sample, initial = 5, step = 0.01, max_iter = 5000) {
  alpha <- initial
  trace <- numeric(max_iter)
  for (i in seq_len(max_iter)) {
    new_alpha <- alpha + step * gradient(alpha, sample)
    trace[i]  <- new_alpha
    if (abs(new_alpha - alpha) < 1e-8) {
      trace <- trace[1:i]
      break
    }
    alpha <- new_alpha
  }
  list(alpha = alpha, trace = trace)
}

result <- grad_ascent_gamma(x_gamma, initial = 5, step = 0.1)
cat("Gradient ascent MLE for alpha:", round(result$alpha, 6), "\n")

plot(result$trace, type = "l", col = "steelblue", lwd = 2,
     xlab = "Iteration", ylab = expression(alpha),
     main = "Gradient Ascent: Gamma Shape MLE")
abline(h = result$alpha, col = "tomato", lty = 2, lwd = 2)
```

> **Tips:**
>
> -   A reasonable starting value might be $\alpha = 1$ or $\alpha = 5$.
> -   If your trace plot looks unstable (oscillating wildly), **reduce the learning rate** (e.g., try `step = 0.01` instead of `0.1`).
> -   If it's converging very slowly, try a **larger learning rate**.

### Verifying with `mle()`

Now let's double-check our gradient ascent answer using `mle()`. This time we estimate **both** $\alpha$ and $\beta$ simultaneously:

```{r gamma-mle-verify}
negloglik_gamma <- function(alpha, beta) {
  if (alpha <= 0 || beta <= 0) return(Inf)
  -sum(dgamma(x_gamma, shape = alpha, scale = beta, log = TRUE))
}

fit_gamma <- mle(negloglik_gamma, start = list(alpha = 1, beta = 1),
                 nobs = length(x_gamma))
```

**Your turn (extension):** The function above uses `dgamma()` to compute the log-likelihood — this is the standard way, and much simpler than writing out the formula by hand.

```{r gamma-optim-verify}
# negloglik_gamma <- function(alpha, beta) {
#   -sum(dgamma( log = TRUE))
# }
```

Now let's fit the model and see the results:

```{r gamma-mle-fit}
fit_gamma <- mle(negloglik_gamma, start = list(alpha = 1, beta = 1),
                 nobs = length(x_gamma))
summary(fit_gamma)
```

### Did it converge?

Remember: **always check convergence!** A convergence code of 0 means success.

```{r gamma-convergence-check}
fit_gamma@details$convergence
cat("Convergence code 0 = success, non-zero = problem.\n")
```

### What if it didn't converge?

Sometimes the algorithm doesn't converge on the first try (especially with tricky distributions like the Gamma). The fix is to **restart from where it left off** and run again. The `while` loop below keeps retrying until it converges:

```{r gamma-convergence-loop}
while (fit_gamma@details$convergence != 0) {
  fit_gamma <- mle(negloglik_gamma, start = as.list(coef(fit_gamma)),
                   nobs = length(x_gamma))
}
cat("Final convergence code:", fit_gamma@details$convergence, "\n")
summary(fit_gamma)
```

> **What's happening here:** Each time the loop runs, it uses the *previous* estimates as the new starting point (`start = as.list(coef(fit_gamma))`). This often helps because the algorithm is now starting from a much better position, making it easier to converge.

------------------------------------------------------------------------

# Quick Reference: Key Concepts

| Term | Plain English |
|------------------------------------|------------------------------------|
| **Likelihood** $L(\theta)$ | "How plausible is this parameter value, given my data?" |
| **Log-likelihood** $\ell(\theta)$ | Same thing, but on a log scale (easier for computers) |
| **MLE** $\hat{\theta}$ | The parameter value that makes the data most plausible |
| **`mle()`** | R function that finds the MLE numerically |
| **`optim()`** | The engine under the hood — general-purpose optimiser |
| **Nelder-Mead** | Slow but robust (no derivatives needed) |
| **BFGS** | Fast and smart (uses gradient information) |
| **Gradient Ascent** | Simplest method — walk uphill step by step |
| **Convergence** | Did the algorithm successfully find the peak? (Check `code == 0`) |
| **Bessel's correction** | Why `sd()` divides by $n-1$ instead of $n$ |
